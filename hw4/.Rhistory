#correlation plot shows that there is a prefect negative linear relationship between
#alcohol and density as well as strong positive correlation between total sulfur dioxide and free #sulfur dioxide . we can model these relationships below.
library(foreach)
k_grid=seq(2,20,by=1)
SSE_grid=foreach (k=k_grid,.combine="c")%do%{cluster_k=kmeans(wine_norm,k,nstart=50)
cluster_k$tot.withinss}
qplot(2:20, SSE_grid, geom=c("point", "line"),
xlab="Number of clusters", ylab="Total within-cluster sum of squares") +
scale_x_continuous(breaks=seq(0, 10, 1)) +
theme_bw()
# k-means with k=3
set.seed(5789)
wine_k3 <- kmeans(wine_norm, centers=3, iter.max=100, nstart=100)
# Using kmeans++ initialization
wine_k3plus = kmeanspp(wine_norm, k=3, iter.max=100, nstart=100)
# Mean values of each cluster
aggregate(wine_norm, by=list(wine_k3$cluster), mean)
aggregate(wine_norm, by=list(wine_k3plus$cluster), mean)
#between cluster sum of squares
wine_k3$betweenss
# k-means with k=3
set.seed(5789)
wine_k3 <- kmeans(wine_norm, centers=3, iter.max=100, nstart=100)
# Using kmeans++ initialization
wine_k3plus = kmeanspp(wine_norm, k=3, iter.max=100, nstart=100)
# Mean values of each cluster
aggregate(wine_norm, by=list(wine_k3$cluster), mean)
aggregate(wine_norm, by=list(wine_k3plus$cluster), mean)
#between cluster sum of squares
wine_k3$betweenss
# Within-cluster sum of squares
wine_k3$withinss
# Total within-cluster sum of squares
wine_k3$tot.withinss
##check what is in what cluster
which(wine_k3$cluster == 1)
which(wine_k3$cluster == 2)
# A few plots with cluster membership shown
qplot(quality, data=wine_norm, color=factor(wine_k3$cluster))
qplot(quality, data=wine_norm, color=factor(wine_k3plus$cluster))
fviz_cluster(list(data = wine_norm, cluster = wine_k3plus$cluster),
ellipse.type = "norm", geom = "point", stand = FALSE,
palette = "jco", ggtheme = theme_classic())
# A few plots with cluster membership shown
qplot(quality, data=wine_norm, color=factor(wine_k3$cluster))
qplot(quality, data=wine_norm, color=factor(wine_k3plus$cluster))
fviz_cluster(list(data = wine_norm, cluster = wine_k3plus$cluster),
ellipse.type = "norm", geom = "point", stand = FALSE,
palette = "jco", ggtheme = theme_classic())
# A few plots with cluster membership shown
qplot(quality, data=wine_norm, color=factor(wine_k3$cluster))
qplot(quality, data=wine_norm, color=factor(wine_k3plus$cluster))
fviz_cluster(list(data = wine_norm, cluster = wine_k3plus$cluster),
ellipse.type = "norm", geom = "point", stand = FALSE,
palette = "jco", ggtheme = theme_classic())
# A few plots with cluster membership shown
qplot(quality, data=wine_norm, color=factor(wine_k3$cluster))
qplot(quality, data=wine_norm, color=factor(wine_k3plus$cluster))
fviz_cluster(list(data = wine_norm, cluster = wine_k3plus$cluster),
ellipse.type = "norm", geom = "point", stand = FALSE,
palette = "jco", ggtheme = theme_classic())
# Clustering
ggpairs(cbind(wine_norm, Cluster=as.factor(wine_k3$cluster)),
columns=6:12, aes(colour=Cluster, alpha=0.5),
lower=list(continuous="points"),
upper=list(continuous="blank"),
axisLabels="none", switch="both") +
theme_bw()
# Clustering
ggpairs(cbind(wine_norm, Cluster=as.factor(wine_k3$cluster)),
columns=1:12, aes(colour=Cluster, alpha=0.5),
lower=list(continuous="points"),
upper=list(continuous="blank"),
axisLabels="none", switch="both") +
theme_bw()
# Clustering
ggpairs(cbind(wine_norm, Cluster=as.factor(wine_k3$cluster)),
columns=1:12, aes(colour=Cluster, alpha=0.5),
lower=list(continuous="points"),
upper=list(continuous="blank"),
axisLabels="none", switch="both") +
theme_bw()
library(ISLR)
modelpca<-prcomp(wine_norm, center=TRUE, scale=TRUE)
names(modelpca)
summary(modelpca)
std_dev <- modelpca$sdev
pr_var <- std_dev^2
prop_varex <- pr_var/sum(pr_var)
plot(cumsum(prop_varex), xlab = "Principal Component",
ylab = "Cumulative Proportion of Variance Explained",
type = "b")
fviz_eig(modelpca, addlabels=TRUE, ylim=c(0,40), geom = c("bar", "line"), barfill = "pink", barcolor="grey",linecolor = "red", ncp=10)+
labs(title = "wine variance - PCA",
x = "Principal Components", y = "% of variances")
#get pca variables
all_var <- get_pca_var(modelpca)
kable(head(all_var$contrib))
library(ISLR)
modelpca<-prcomp(wine_norm, center=TRUE, scale=TRUE)
#names(modelpca)
kable(summary(modelpca))
library(ISLR)
modelpca<-prcomp(wine_norm, center=TRUE, scale=TRUE)
#names(modelpca)
summary(modelpca)
std_dev <- modelpca$sdev
pr_var <- std_dev^2
prop_varex <- pr_var/sum(pr_var)
plot(cumsum(prop_varex), xlab = "Principal Component",
ylab = "Cumulative Proportion of Variance Explained",
type = "b")
fviz_eig(modelpca, addlabels=TRUE, ylim=c(0,40), geom = c("bar", "line"), barfill = "pink", barcolor="grey",linecolor = "red", ncp=10)+
labs(title = "wine variance - PCA",
x = "Principal Components", y = "% of variances")
#get pca variables
all_var <- get_pca_var(modelpca)
kable(head(all_var$contrib))
#get pca variables
all_var <- get_pca_var(modelpca)
kable(head(all_var$contrib))
modelpca<-prcomp(wine_norm, center=TRUE, scale=TRUE)
#names(modelpca)
summary(modelpca)
#names(modelpca)
summary(modelpca)%>%kable_as_image() #<- shows importance of each components
#names(modelpca)
summary(modelpca)%>%kable() #<- shows importance of each components
#names(modelpca)
summary(modelpca)%>%as.table() #<- shows importance of each components
# Clustering
ggpairs(cbind(wine_norm, Cluster=as.factor(wine_k3$cluster)),
columns=1:12, aes(colour=Cluster, alpha=0.5),
lower=list(continuous="points"),
upper=list(continuous="blank"),
axisLabels="none", switch="both") +
theme_bw()
# Clustering
ggpairs(cbind(wine_norm, Cluster=as.factor(wine_k3$cluster)),
columns=1:12, aes(colour=Cluster, alpha=0.5),
lower=list(continuous="points"),
upper=list(continuous="blank"),
axisLabels="none", switch="both") +
theme_bw()
social_marketing <- read.csv("C:/Users/anuka/Desktop/Spring 2021/ECO 395M - DATA MINING/Data/social_marketing.csv")
View(social_marketing)
marketing <- read.csv("C:/Users/anuka/Desktop/Spring 2021/ECO 395M - DATA MINING/Data/social_marketing.csv")
kable(head(marketing))
str(marketing)
#str(marketing)
marketing$X<-as.factor(marketing$X)
str(marketing)
# as in question 1 i want to create corr matrix
corr<-corr(marketing[c(2:37)])
# as in question 1 i want to create corr matrix
corr<-cor(marketing[c(2:37)])
corrplot(corr, method="ellipse",, type="upper", tl.cex=0.9)
corrplot(corr, method="ellipse",, type="upper", tl.cex=0.7)
corrplot(corr, method="ellipse",, type="upper", tl.cex=0.6)
corrplot(corr, method="ellipse",, type="upper", tl.cex=0.7)
corrplot(corr, method="ellipse",, type="upper", tl.cex=0.8)
corrplot(corr, method="ellipse",, type="upper", tl.cex=0.9)
# We start with standardizing variables
market_norm<-scale(market[,2:37], center=TRUE, scale=TRUE)
# We start with standardizing variables
market_norm <-scale(market[,2:37], center=TRUE, scale=TRUE)
# We start with standardizing variables
marketing_norm <-scale(marketing[,2:37], center=TRUE, scale=TRUE)
# see whats the center ( mean ) and std. dev for standardized data
mean=attr(marketing_norm$center)
sd.dev=attr(marketing_norm$scale)
# see whats the center ( mean ) and std. dev for standardized data
mean=attr(marketing_norm, "scaled::center")
sd.dev=attr(marketing_norm, "scaled::scale")
print(mean)
print(sd.dev)
# We start with standardizing variables
marketing_norm <-scale(marketing[,2:37], center=TRUE, scale=TRUE)
# see whats the center ( mean ) and std. dev for standardized data
mean=attr(marketing_norm, "scaled::center")
print(mean)
library(foreach)
k_grid=seq(2,20,by=1)
SSE_grid=foreach (k=k_grid,.combine="c")%do%{cluster_k=kmeans(marketing_norm,k,nstart=50)
cluster_k$tot.withinss}
qplot(2:20, SSE_grid, geom=c("point", "line"),
xlab="Number of clusters", ylab="Total within-cluster sum of squares") +
scale_x_continuous(breaks=seq(0, 10, 1)) +
theme_bw()
knitr::opts_chunk$set(echo = TRUE,
warning=FALSE,
message=FALSE,
echo=FALSE,
fig_caption: TRUE
header-includes: \usepackage{caption})
knitr::opts_chunk$set(echo = TRUE,
warning=FALSE,
message=FALSE,
echo=FALSE,
fig_caption: yes
header-includes: \usepackage{caption})
knitr::opts_chunk$set(echo = TRUE,
warning=FALSE,
message=FALSE,
echo=FALSE
)
library(foreach)
k_grid=seq(2,20,by=1)
SSE_grid=foreach (k=k_grid,.combine="c")%do%{cluster_k=kmeans(marketing_norm,k,nstart=50)
cluster_k$tot.withinss}
library(foreach)
k_grid=seq(1,10,by=1)
SSE_grid=foreach (k=k_grid,.combine="c")%do%{cluster_k=kmeans(marketing_norm,k,nstart=50)
cluster_k$tot.withinss}
qplot(2:20, SSE_grid, geom=c("point", "line"),
xlab="Number of clusters", ylab="Total within-cluster sum of squares") +
scale_x_continuous(breaks=seq(0, 10, 1)) +
theme_bw()
library(foreach)
k_grid=seq(1,10,by=1)
SSE_grid=foreach (k=k_grid,.combine="c")%do%{cluster_k=kmeans(marketing_norm,k,nstart=50)
cluster_k$tot.withinss}
qplot(1:10, SSE_grid, geom=c("point", "line"),
xlab="Number of clusters", ylab="Total within-cluster sum of squares") +
scale_x_continuous(breaks=seq(0, 10, 1)) +
theme_bw()
set.seed(1234)
cluster5<-kmeans(marketing_norm,k=5,nstart=25)
cluster5<-kmeans(marketing_norm, 5,nstart=25)
fviz_cluster(cluster5, data=marketin_norm, ellipse.type="euclid", ggtheme=theme_classic(), geom="point")
fviz_cluster(cluster5, data=marketing_norm, ellipse.type="euclid", ggtheme=theme_classic(), geom="point")
#start clustering with K=5
set.seed(1234)
cluster5<-kmeans(marketing_norm, 5,nstart=25)
#for visualizing clusters I found the package factoExtra that does beautiful plots for clustering
# we need to use fviz_cluster like I did in Q1
#?fviz_cluster
fviz_cluster(cluster5, data=marketing_norm, ellipse.type="euclid", ggtheme=theme_classic(), geom="point", main="Cluster Plot for K=5")
#start clustering with K=5
set.seed(1234)
cluster5<-kmeans(marketing_norm, 5,nstart=25)
#for visualizing clusters I found the package factoExtra that does beautiful plots for clustering
# we need to use fviz_cluster like I did in Q1
#?fviz_cluster
fviz_cluster(cluster5, data=marketing_norm, ellipse.type="euclid", ggtheme=theme_classic(), geom="point", main="**Cluster Plot for K=5**")
market_segments<-aggregate(marketing, by=list(cluster=cluster5$cluster), median())
market_segments<-aggregate(marketing, by=list(cluster=cluster5$cluster), mean)
market_segments<-aggregate(marketing, by=list(cluster=cluster5$cluster), median)
market_segments<-aggregate(marketing, by=list(cluster=cluster5$cluster), mean)
kable(head(market_segments))
market_segment_t<-transpose(market_segments)
kable(head(market_segment_t))
market_segment_t<-transpose(market_segments)
rownames(market_segment_t)<-colnames(market_segment)
rownames(market_segment_t)<-colnames(market_segments)
market_segments<-aggregate(marketing, by=list(cluster=cluster5$cluster), mean)%>%as.data.frame()
kable(head(market_segments))
market_segment_t<-transpose(market_segments)
rownames(market_segment_t)<-colnames(market_segments)
kable(head(market_segments))
#I am going to remove X varible which is ID numbers and unnecessary for our purposes
market_segments$X<-market_segments$X==NULL
#I am going to remove X varible which is ID numbers and unnecessary for our purposes
market_segments$X<-market_segments$X=NULL
#I am going to remove X varible which is ID numbers and unnecessary for our purposes
market_segments$X=market_segments$X=NULL
kable(head(market_segments))
market_segment_t<-transpose(market_segments)
rownames(market_segment_t)<-colnames(market_segments)
kable(head(market_segments))
market_segment_t<-transpose(market_segments)
kable(head(market_segment_t))
# Which segments  are in which clusters?
which(market_segments$cluster == 1)
# Which segments  are in which clusters?
which(market_segments$cluster == 1)
# Which segments  are in which clusters?
which(cluster5$cluster == 1)
kable(head(market_segments))
market_segments$chatter=market_segments$chatter=NULL
market_segments<-aggregate(marketing, by=list(cluster=cluster5$cluster), mean)%>%as.data.frame()
#I am going to remove X varible which is ID numbers and unnecessary for our purposes
market_segments$X=market_segments$X=NULL
market_segments$chatter=market_segments$chatter=NULL
kable(head(market_segments))
# transpose
market_segment_t<-t(market_segments)
# get row and colnames in order
colnames(market_segment_t) <- rownames(market_segments)
rownames(market_segment_t) <- colnames(market_segments)
#segment profiles
market_segments<-aggregate(marketing, by=list(cluster=cluster5$cluster), mean)%>%as.data.frame()
#I am going to remove X varible which is ID numbers and unnecessary for our purposes
market_segments$X=market_segments$X=NULL
market_segments$chatter=market_segments$chatter=NULL
kable(head(market_segments))
# transpose
market_segment_t<-t(market_segments)
# get row and colnames in order
colnames(market_segment_t) <- rownames(market_segments)
rownames(market_segment_t) <- colnames(market_segments)
# REmoving cluster names
market_segment_t2 = market_segment_t[-1,]
k = colnames(market_segment_t2)[apply(market_segment_t2,1,which.max)]
features = cbind(rownames(market_segment_t2),k)
features = cbind(rownames(market_segment_t2),k)
print(features)
print(features)%>%kable()
features = cbind(rownames(market_segment_t2),k)%>%kable()
features = cbind(rownames(market_segment_t2),k)%>%kable()
knitr::opts_chunk$set(echo = TRUE,
warning=FALSE,
message=FALSE,
echo=FALSE
)
#load libraries
library(dplyr)
library(gridExtra)
library(tidytext)
library(wordcloud2)
library(randomForest)
library(caret)
library(tm)
library(slam)
library(proxy)
library(tidytext)
#load data
#reader plain
readerPlain = function(fname){
readPlain(elem=list(content=readLines(fname)),
id=fname, language='en') }
#load libraries
library(dplyr)
library(gridExtra)
library(tidytext)
library(wordcloud2)
library(randomForest)
library(caret)
library(tm)
library(slam)
library(proxy)
library(tidytext)
#load data
#reader plain # https://gist.github.com/jgscott/28d9d1287a0c3c1477e2113f6758d5ff
readerPlain = function(fname){
readPlain(elem=list(content=readLines(fname)),
id=fname, language='en') }
readerPlain = function(fname){
readPlain(elem=list(content=readLines(fname)),
id=fname, language='en') }
train_data <- Sys.glob("https://github.com/jgscott/ECO395M/tree/master/data/ReutersC50/C50train")
file_list_train <- NULL
class_labels_train <- NULL
for (name in train_data){
file_list_train <- c(file_list_train, Sys.glob(paste0("https://github.com/jgscott/ECO395M/tree/master/data/ReutersC50/C50train", name,"/*.txt")))
class_labels_train <- c(class_labels_train, rep(name, each = length(Sys.glob(paste0("https://github.com/jgscott/ECO395M/tree/master/data/ReutersC50/C50train", name,'/*.txt')))))
}
train_data
## "globbing" = expanding wild cards in filename paths
for (name in train_data){
file_list_train <- c(file_list_train, Sys.glob(paste0("https://github.com/jgscott/ECO395M/tree/master/data/ReutersC50/C50train/*", name,"/*.txt")))
class_labels_train <- c(class_labels_train, rep(name, each = length(Sys.glob(paste0("https://github.com/jgscott/ECO395M/tree/master/data/ReutersC50/C50train/*", name,'/*.txt')))))
}
all_files_train <- lapply(file_list_train, readerPlain)
file_list_train
# Clean up the file names
mynames = file_list_train %>%
{ strsplit(., "/", fixed=TRUE) } %>%
{ lapply(., tail, n=2) } %>%
{ lapply(., paste0, collapse = "") } %>%
unlist
# Clean up the file names
mynames = file_list_train %>%
{ strsplit("/", fixed=TRUE) } %>%
{ lapply(tail, n=2) } %>%
{ lapply(paste0, collapse = "") } %>%
unlist
# Clean up the file names
mynames = file_list_train %>%
{ strsplit("/") } %>%
{ lapply(tail, n=2) } %>%
{ lapply(paste0, collapse = "") } %>%
unlist
# Clean up the file names
mynames = file_list_train %>%
strsplit("/") %>%
lapply(tail,n = 2) %>%
lapply(paste0, collapse = "") %>%
unlist
train_data <- Sys.glob("https://github.com/jgscott/ECO395M/tree/master/data/ReutersC50/C50train/*")
file_list_train <- NULL
class_labels_train <- NULL
## "globbing" = expanding wild cards in filename paths
for (name in train_data){
file_list_train <- c(file_list_train, Sys.glob(paste0("https://github.com/jgscott/ECO395M/tree/master/data/ReutersC50/C50train/*", name,"/*.txt")))
class_labels_train <- c(class_labels_train, rep(name, each = length(Sys.glob(paste0("https://github.com/jgscott/ECO395M/tree/master/data/ReutersC50/C50train/*", name,'/*.txt')))))
}
all_files_train <- lapply(file_list_train, readerPlain)
#reader plain # https://gist.github.com/jgscott/28d9d1287a0c3c1477e2113f6758d5ff
readerPlain = function(fname){
readPlain(elem=list(content=readLines(fname)),
id=fname, language='en') }
# Clean up the file names
mynames = file_list_train %>%
strsplit("/") %>%
lapply(tail,n = 2) %>%
lapply(paste0, collapse = "") %>%
unlist
train_data <- Sys.glob("https://github.com/jgscott/ECO395M/tree/master/data/ReutersC50/C50train")
file_list_train <- NULL
class_labels_train <- NULL
## "globbing" = expanding wild cards in filename paths
for (name in train_data){
file_list_train <- c(file_list_train, Sys.glob(paste0("https://github.com/jgscott/ECO395M/tree/master/data/ReutersC50/C50train", name,"/*.txt")))
class_labels_train <- c(class_labels_train, rep(name, each = length(Sys.glob(paste0("https://github.com/jgscott/ECO395M/tree/master/data/ReutersC50/C50train", name,'/*.txt')))))
}
all_files_train <- lapply(file_list_train, readerPlain)
#reader plain # https://gist.github.com/jgscott/28d9d1287a0c3c1477e2113f6758d5ff
readerPlain = function(fname){
readPlain(elem=list(content=readLines(fname)),
id=fname, language='en') }
# Clean up the file names
mynames = file_list_train %>%
strsplit("/") %>%
lapply(tail,n = 2) %>%
lapply(paste0, collapse = "") %>%
unlist
## Rolling two directories together into a single training corpus
train_dirs <- Sys.glob('https://github.com/jgscott/ECO395M/tree/master/data/ReutersC50/C50train/*')
# train_dirs <- train_dirs[c(43, 47)]
file_list <- NULL
labels_train <- NULL
for (author in train_dirs) {
author_name = substring(author, first = 29)
files_to_add = Sys.glob(paste0(author, '/*.txt'))
file_list = append(file_list, files_to_add)
labels_train = append(labels_train, rep(author_name, length(files_to_add)))
}
corpus_train <- Corpus(DirSource(train_dirs))
list.files
?list.files
# read in train data and create DTM
author_names_train <- dir("./ReutersC50/C50train")
author_names_train
# read in train data and create DTM
author_names_train <- dir("https://github.com/jgscott/ECO395M/tree/master/data/ReutersC50/C50train")
author_names_train
file_list_train <- NULL
class_labels_train <- NULL
for (name in author_names_train){
file_list_train <- c(file_list_train, Sys.glob(paste0('./ReutersC50/C50train/', name,'/*.txt')))
class_labels_train <- c(class_labels_train, rep(name, each = length(Sys.glob(paste0('./ReutersC50/C50train/', name,'/*.txt')))))
}
# define the function that will read in the files
readerPlain = function(fname){
readPlain(elem = list(content = readLines(fname)),
id = fname, language = 'en') }
# read in the files and store them as a list
all_files_train <- lapply(file_list_train, readerPlain)
# give each file a representative name
file_names_train <- file_list_train %>%
strsplit("/") %>%
lapply(tail,n = 2) %>%
lapply(paste0, collapse = "") %>%
unlist
# read in train data and create DTM
author_train <- dir("https://github.com/jgscott/ECO395M/tree/master/data/ReutersC50/C50train")
file_list_train <- NULL
class_labels_train <- NULL
for (name in author_names_train){
file_list_train <- c(file_list_train, Sys.glob(paste0('./ReutersC50/C50train/', name,'/*.txt')))
class_labels_train <- c(class_labels_train, rep(name, each = length(Sys.glob(paste0('./ReutersC50/C50train/', name,'/*.txt')))))
}
library(dplyr)
library(gridExtra)
library(tidytext)
library(wordcloud2)
library(randomForest)
library(caret)
library(tm)
library(slam)
library(proxy)
library(tidytext
# read in train data and create DTM
author_train <- dir("https://github.com/jgscott/ECO395M/tree/master/data/ReutersC50/C50train")
# read in train data and create DTM
author_train <- dir("https://github.com/jgscott/ECO395M/tree/master/data/ReutersC50/C50train/*")
author_train
for (name in author_train){
file_list_train <- c(file_list_train, Sys.glob(paste0('./ReutersC50/C50train/', name,'/*.txt')))
class_labels_train <- c(class_labels_train, rep(name, each = length(Sys.glob(paste0('./ReutersC50/C50train/', name,'/*.txt')))))
}
# define the function that will read in the files
readerPlain = function(fname){
readPlain(elem = list(content = readLines(fname)),
id = fname, language = 'en') }
# read in the files and store them as a list
all_files_train <- lapply(file_list_train, readerPlain)
file_list_train <- NULL
# define the function that will read in the files
readerPlain = function(fname){
readPlain(elem = list(content = readLines(fname)),
id = fname, language = 'en') }
# read in the files and store them as a list
all_files_train <- lapply(file_list_train, readerPlain)
# give each file a representative name
file_names_train <- file_list_train %>%
strsplit("/") %>%
lapply(tail,n = 2) %>%
lapply(paste0, collapse = "") %>%
unlist
head(author_train)
