---
title: "Data_Mining_HW3"
author: "Anuka Revi"
date: "3/29/2021"
output:
  html_document: default
  pdf_document: default
---

#Load All libraries
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, 
                      cache = TRUE,
                      warning = FALSE, 
                      message = FALSE)
 
library(knitr)
library(dplyr)
library(gridExtra)
library(ggplot2)
library(ggthemes)
library(cowplot)
library(moments)
library(caret)
library(glmnet)
library(kableExtra)
library(olsrr)
library(ggmap)
library(skimr)
library(RColorBrewer)
library(plotly)
library(readr)
library(caret)
library(lmtest)
library(nortest)
library(scales)
library(rsample)
library(rpart)
library(rpart.plot)
library(pls)

```

Q3 - California Housing

```{r California Map}
CAhousing <- read.csv("C:/Users/anuka/Desktop/Spring 2021/ECO 395M - DATA MINING/Data/CAhousing.csv")
dim<-dim(CAhousing)
dim[1]
dim[2]
# we see that there are 20640 houses with 9 given characteristics

#data cleaning
skim(CAhousing)
head(CAhousing)

#By looking at data we see that there are no missing varialbes and data looks clean so we can start analysis.


#create map

plot_map = ggplot(CAhousing, 
                  aes(x = longitude, y = latitude, color = medianHouseValue, 
                      hma = housingMedianAge, tr = totalRooms, tb = totalBedrooms,
                      hh = households, mi=medianIncome)) +
  geom_point(aes(size = population), alpha = 0.4) +
  xlab("Longitude") +
  ylab("Latitude") +
  ggtitle("Data Map - Longtitude vs Latitude and Associated Variables") +
  theme(plot.title = element_text(hjust = 0.5)) +
  scale_color_distiller(palette = "Paired", labels = comma) +
  labs(color = "Median House Value (in $USD)", size = "Population")
plot_map

```


Map shows that houses located inland have lower median house value, while coastal houses have higher values.

```{r Train_Test Split}
#Train test splits with X-validation
set.seed(420)

CAhousing_split=initial_split(CAhousing, prop=0.8,strata=medianHouseValue)

CAhousing_train=training(CAhousing_split)
CAhousing_test=testing(CAhousing_split)

#vfold
CAhousing_vfold=vfold_cv(CAhousing_train, v=10, strata=medianHouseValue)

```

# **Model Selection**

As a starting point I create 3 initial models that will be fitted on our training data. First model uses all the variables, the second one uses two-way interactions between all the variables & third one uses 3 way interactions.

```{r model selection}
full_model = lm(medianHouseValue ~ ., data = CAhousing_train)
full_model_adjr2 = summary(full_model)$adj.r.squared

full_twoway_model = lm(medianHouseValue ~ (.)^2, data = CAhousing_train)
full_twoway_adjr2 = summary(full_twoway_model)$adj.r.squared

full_threeway_model = lm(medianHouseValue ~ (.)^3, data = CAhousing_train)
full_threeway_adjr2 = summary(full_threeway_model)$adj.r.squared
```

We will be using model selection criteria AIC and adj. R^2 

```{r AIC total predictors}
beginning_mods_results = data.frame(
  "Total Predictors" =
    c("Full Model" = extractAIC(full_model)[1],
      "Two-Way Int. Model" = extractAIC(full_twoway_model)[1],
      "Three-Way Int. Model" = extractAIC(full_threeway_model)[1]),
  "AIC" =
    c("Full Model" = extractAIC(full_model)[2],
      "Two-Way Int. Model" = extractAIC(full_twoway_model)[2],
      "Three-Way Int. Model" = extractAIC(full_threeway_model)[2]),
  "Adj R-Squared" =
    c("Full Model" = full_model_adjr2,
      "Two-Way Int. Model" = full_twoway_adjr2,
      "Three-Way Int. Model" = full_threeway_adjr2))

kable(beginning_mods_results, align = c("c", "r"))

```

As we see three way model has the lowest AIC, howevere it has far more predictors that renders this model to be more complex. 

All three of this candidates are good for stepwise selection but since three way model was the best one, i will just use full model and two-way model for stepwise selection. 

```{r stepwise for full and 2-way model}
#full_model AIC vs BIC
step_full_mod_finish_aic =  stats::step(full_model, direction = "both", trace = 0)

n = length(resid(full_model))
step_full_mod_finish_bic =  stats::step(full_model, direction = "both", k = log(n), trace = 0)

#2way model AIC vs BIC
step_twoway_mod_finish_aic = stats:: step(full_twoway_model, direction = "both", trace = 0)

n = length(resid(full_twoway_model))
step_twoway_mod_finish_bic =  stats::step(full_twoway_model, direction = "both", k = log(n), trace = 0)
```

```{r AIC  as data .frame}
aic_results = data.frame(
  "AIC" =
    c("Step" =
        c("full" = extractAIC(step_full_mod_finish_aic)[2],
          "Two-Way" = extractAIC(step_twoway_mod_finish_aic)[2],
           "Three-way" = extractAIC(full_threeway_model)[2])))
  

kable(aic_results)


```

We see that initial three way model beats both stepwise models using full and 2 way model as starting points, but since 3 way model is too complex I will choose the next best model which is stepwise selection of 2-way interaction model, since it has the lowest AIC after a 3-way model.  

```{r fitted  vs residual model}
diagnostics = function(model, alpha = .05, pointcol = "orange", linecol = "blue", plots = TRUE, tests = TRUE, pointtype = 16) {
    if (plots == TRUE) {
        par(mfrow = c(1, 3))
        plot(
                fitted(model),
                resid(model),
                pch = pointtype,
                xlab = "Fitted Values",
                ylab = "Residuals",
                main = "Fitted vs Residuals",
                col = pointcol
            )
        abline(h = 0, lwd = 2, col = linecol)
        
        qqnorm(
                resid(model),
                pch = pointtype,
                main = "QQNorm Plot",
                col = pointcol
            )
        qqline(
                resid(model),
                lwd = 2,
                col = linecol
                )
        hist(
            resid(model),
            main = "Histogram of Residuals",
            col = pointcol,
            xlab = "Residuals",
            ylab = "Frequency"
            )
    }}
    

```

I will transform MedianHouseValue in logs to get better estimation and draw fitted vs residual graph.


```{r}
#log housevalue
step_twoway_mod_finish_aic_log = lm(formula=log(medianHouseValue)~(.)^2, data=CAhousing_train)
diagnostics(step_twoway_mod_finish_aic_log)
```

Now I will use LOOCV RMSE as my final model selection criteria.

```{r use LOOCV}
# From the text: http://daviddalpiaz.github.io/appliedstats/variable-selection-and-model-building.html
calc_loocv_rmse = function(model) {
  sqrt(mean((resid(model) / (1 - hatvalues(model))) ^ 2))
}
calc_rmse = function(actual, predicted) {
  sqrt(sum((actual - predicted)^2) / length(actual)) 
}
calc_avg_per_error = function(actual, predicted) {
    inter_abs = abs(predicted - actual)
    100 * (sum(inter_abs / actual)) / length(actual)
}

#for my models - full, step 2_way model, 3_way model

full_loocv_rmse = calc_loocv_rmse(step_full_mod_finish_aic)
twoway_loocv_rmse = calc_loocv_rmse(step_twoway_mod_finish_aic)
threeway_loocv_rmse = calc_loocv_rmse(full_threeway_model)

loocv_rmse_results = data.frame(
  "LOOCV-RMSE" =
    c("Step full" = full_loocv_rmse,
      "Step Two-Way-Log" = twoway_loocv_rmse,
      "Initial Three-way" = threeway_loocv_rmse))

kable(loocv_rmse_results)

```

We see that LOOCV RMSE is still smaller for initial 3-way model so I will keep using this as my best model. I will evaluate this model on the test set to see how the model perfomrs on unseen data.

```{r}
# the actual median house values from the test set
test_actual = CAhousing_test$medianHouseValue
# the predicted house values for the test set
#test_predictions1 = predict(full_threeway_model, CAhousing_test)
#VS log scaled step_twoway
test_predictions2 = predict(step_twoway_mod_finish_aic_log, CAhousing_test)
# the RMSE
#test_rmse = calc_rmse(test_actual, test_predictions1)
test_rmse_2=calc_rmse(test_actual, test_predictions2)
# the percentage error
#test_perc_error1 = calc_avg_per_error(test_actual, test_predictions1)
test_perc_error2 = calc_avg_per_error(test_actual, test_predictions2)

test_rmse
```

I obtained RMSE of 67082 on test set that is considerably higher than on the training set (RMSE_train= 64939.72), which although is undesirable is not unusual. 

Now we can plot our model' errors in the test data.

```{r}
plot_map = ggplot(CAhousing_test, 
                  aes(x = longitude, y = latitude, 
                      color = test_predictions - test_actual, 
                      hma = housingMedianAge, tr = totalRooms, tb = totalBedrooms,
                      hh = households, mi = medianIncome)) +
              geom_point(aes(size = abs(test_predictions - test_actual)), alpha = 0.4) +
              xlab("Longitude") +
              ylab("Latitude") +
              ggtitle("Predicted Price Over / Under Actual Price") +
              theme(plot.title = element_text(hjust = 0.5)) +
              scale_color_distiller(palette = "Paired", labels = comma) +
              labs(color = "Predicted Price Over / Under (in $USD)", 
                   size = "Magnitude of Price Difference")
plot_map

```

Q2 - green certificate

```{r}
greenbuildings <- read.csv("C:/Users/anuka/Desktop/Spring 2021/ECO 395M - DATA MINING/Data/greenbuildings.csv")

#create new variable = revenue /sqft/yr and collapse green rating into one category 
green_build<-greenbuildings %>%
  janitor::clean_names()%>%
  mutate(rev_sqft_yr=rent*leasing_rate,green_certified = if_else(green_rating == 1, "Green", "Non-green"))


skim(green_build)
```


I am going to visualize the distribution for *revenue / sq.ft.* variable for green vs non-green buildings. The graph below shows the right-skewed distribution and to resolve this issue, I will be working with log transformed  revenue per square foot variable. 


```{r}
#visualize 
# Histogram of revenue per sq. foot :
ggplot(green_build, aes(x = rev_sqft_yr)) +
  geom_vline(aes(xintercept = mean(rev_sqft_yr)),color = "red", linetype = 2) +xlim(0,12000)+
  geom_histogram(color = "black", bins=40, fill="gray") +
  labs(x = "revenue/Sq.Ft/Year", title = "Distribution of Revenue per Square Foot for Green vs Non-Green Buildings")+facet_wrap(.~green_certified)


```
In order to build the best predictive model I will use Principal Component Regression. Realizing that many features determining house prices are highly correlated (for instance building quality could be related to whether or not the building has overgone some recent renovations), PCR can help us reduce the dimensionality of the feature space and minimize such correlations. However, since PCR works best with numerical variables I will drop all factor variables from the training set.

Test/Train sets here:

```{r}
#train test split
set.seed(420)
green_split <- initial_split(green_build, strata = rev_sqft_yr)
green_train <- training(green_split)
green_test <- testing(green_split)

green_folds <- vfold_cv(green_train, strata = rev_sqft_yr)
green_folds

#drop string variables
green_train_num<-subset(green_train, select=c("rev_sqft_yr", "cd_total_07","gas_costs","leasing_rate","hd_total07","electricity_costs", "size", 
                                                 "stories","total_dd_07", "city_market_rent","age", "precipitation"))



pcr.revenue <- pcr(rev_sqft_yr ~ ., data=green_train_num, scale = TRUE,
                   validation="CV")
# Plot model RMSE vs different values of components
plot(pcr.revenue)

# Print the best tuning parameter ncomp that
# minimize the cross-validation error, RMSE
pcr.revenue$bestTune

# Summarize the final model
summary(pcr.revenue$finalModel)

# Make predictions
predictions <- pcr.revenue %>% predict(green_test)
predictions

# Model performance metrics
data.frame(
  RMSE = caret::RMSE(predictions, green_test$rev_sqft_yr),
  Rsquare = caret::R2(predictions, green_test$rev_sqft_yr)
)

#Try random forests

```






